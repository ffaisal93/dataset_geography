{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T16:27:06.943687Z",
     "start_time": "2021-12-19T16:27:06.941512Z"
    }
   },
   "outputs": [],
   "source": [
    "# from transformers.data.processors.squad import SquadResult, SquadV1Processor\n",
    "\n",
    "# processor = SquadV1Processor()\n",
    "# examples = processor.get_dev_examples(args.data_dir, filename=args.predict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T16:27:19.356686Z",
     "start_time": "2021-12-19T16:27:07.916868Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import collections\n",
    "from squad import SquadResult, SquadV1Processor, SquadV2Processor\n",
    "from squad_metrics import (\n",
    "    compute_predictions_log_probs,\n",
    "    compute_predictions_logits,\n",
    "    squad_evaluate,\n",
    ")\n",
    "\n",
    "cached_features_file='tydiqa/cached_dev_tydiqa-gold_384_'\n",
    "pred_file='tydiqa/predictions_.json'\n",
    "features_and_dataset = torch.load(cached_features_file)\n",
    "\n",
    "examples = features_and_dataset[\"examples\"]\n",
    "predictions=json.load(open(pred_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T19:06:49.604878Z",
     "start_time": "2021-12-18T19:06:49.265059Z"
    }
   },
   "outputs": [],
   "source": [
    "langs = ['swahili','bengali','arabic','korean','english','indonesian','japanese','russian',\n",
    "        'telugu','finnish','thai']\n",
    "\n",
    "for lan in langs:\n",
    "    name = lan+'--'\n",
    "    new_examples=[]\n",
    "    new_preds=collections.OrderedDict()\n",
    "    for exam in examples:\n",
    "        if exam.qas_id.startswith(name)==True:\n",
    "            new_examples.append(exam)\n",
    "            new_preds[exam.qas_id]=predictions[exam.qas_id]\n",
    "    if len(new_examples)!=0:\n",
    "        results = squad_evaluate(new_examples, new_preds)\n",
    "        print(name)\n",
    "        print(results)\n",
    "\n",
    "for lan in langs[:-1]:\n",
    "    name = lan+'-english--'\n",
    "    new_examples=[]\n",
    "    new_preds=collections.OrderedDict()\n",
    "    for exam in examples:\n",
    "        if exam.qas_id.startswith(name)==True:\n",
    "            new_examples.append(exam)\n",
    "            new_preds[exam.qas_id]=predictions[exam.qas_id]\n",
    "    if len(new_examples)!=0:\n",
    "        results = squad_evaluate(new_examples, new_preds)\n",
    "        print(name)\n",
    "        print(results)\n",
    "\n",
    "for lan in langs[:-1]:\n",
    "    name = 'english-'+lan+'--'\n",
    "    new_examples=[]\n",
    "    new_preds=collections.OrderedDict()\n",
    "    for exam in examples:\n",
    "        if exam.qas_id.startswith(name)==True:\n",
    "            new_examples.append(exam)\n",
    "            new_preds[exam.qas_id]=predictions[exam.qas_id]\n",
    "    if len(new_examples)!=0:\n",
    "        results = squad_evaluate(new_examples, new_preds)\n",
    "        print(name)\n",
    "        print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T15:51:41.070564Z",
     "start_time": "2021-12-19T15:51:41.063589Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import pickle\n",
    "\n",
    "def get_qdata(filename):\n",
    "\n",
    "    with open(filename,'r') as f:\n",
    "        data=json.loads(f.read())\n",
    "    mlqa_q={}\n",
    "    i=0\n",
    "    for dat in data['data']:\n",
    "    #     if i>2:\n",
    "    #         break\n",
    "    #     print(dat)\n",
    "        for par in dat['paragraphs']:\n",
    "            for qos in par['qas']:\n",
    "                mlqa_q[qos['id']] = qos['question'].strip()\n",
    "                i+=1\n",
    "    print(i, len(mlqa_q))\n",
    "    if i!=len(mlqa_q):\n",
    "        mlqa_q={}\n",
    "        i=0\n",
    "        for dat in data['data']:\n",
    "        #     if i>2:\n",
    "        #         break\n",
    "        #     print(dat)\n",
    "            for par in dat['paragraphs']:\n",
    "                for qos in par['qas']:\n",
    "                    if qos['id'] not in mlqa_q:\n",
    "                        mlqa_q[qos['id']]=[qos['question'].strip()]\n",
    "                    else:\n",
    "                        mlqa_q[qos['id']].append(qos['question'].strip())\n",
    "                    i+=1\n",
    "        print(i, len(mlqa_q))        \n",
    "    return mlqa_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T15:58:14.864319Z",
     "start_time": "2021-12-19T15:58:13.403521Z"
    }
   },
   "outputs": [],
   "source": [
    "from wikidata.client import Client\n",
    "import json\n",
    "import os\n",
    "\n",
    "json_name = 'tydiqa_data/all_d.json'\n",
    "with open(json_name) as inp:\n",
    "    jsonstr = inp.read()\n",
    "ent_ids = json.loads(jsonstr)\n",
    "\n",
    "json_name = 'country_dict.json'\n",
    "with open(json_name) as inp:\n",
    "    jsonstr = inp.read()\n",
    "countries = json.loads(jsonstr)\n",
    "\n",
    "json_name = 'id2geo.json'\n",
    "with open(json_name) as inp:\n",
    "    jsonstr = inp.read()\n",
    "id2geo = json.loads(jsonstr)\n",
    "\n",
    "json_name = 'place2country.json'\n",
    "with open(json_name) as inp:\n",
    "    jsonstr = inp.read()\n",
    "place2coun = json.loads(jsonstr)\n",
    "\n",
    "def get_orig_id_ent(id_ques,all_q_id, all_ent):\n",
    "    client = Client()\n",
    "    orig_id_ent={}\n",
    "    tags=['country','citizen','born','died']\n",
    "    for ids,q in id_ques.items():\n",
    "        lang=ids.split('-')[0]\n",
    "        if q in all_q_id[lang]:\n",
    "            ent=all_ent[lang][int(all_q_id[lang][q])]\n",
    "            orig_id_ent[ids]=[]\n",
    "            if ent in ent_ids:\n",
    "    #             print(q,ent_ids[ent],ent)\n",
    "                for x,j in ent_ids[ent].items():\n",
    "                    if x in tags:\n",
    "                        if j in countries: \n",
    "                            orig_id_ent[ids].append(countries[j])\n",
    "                        elif j in id2geo:\n",
    "                            orig_id_ent[ids].append(id2geo[j]['country'])\n",
    "                        elif j in place2coun:\n",
    "                            orig_id_ent[ids].append(place2coun[j]['country'])\n",
    "                        else:\n",
    "                            place = client.get('Q745956', load=True)\n",
    "                            for key2 in place.keys():\n",
    "                                if key2.id == 'P17':\n",
    "                                    try:\n",
    "                                        countryid = place[key2].id\n",
    "                                        orig_id_ent[ids].append(countries[countryid])\n",
    "#                                         print(x,j,countries[countryid])\n",
    "                                    except:\n",
    "                                        print(key2,  place)\n",
    "                orig_id_ent[ids]=set(orig_id_ent[ids])\n",
    "    return orig_id_ent\n",
    "\n",
    "def get_coun2ids(orig_id_ent):\n",
    "    coun2ids={}\n",
    "    for ids, coun in orig_id_ent.items():\n",
    "        if len(coun)!=0:\n",
    "            for x in coun:\n",
    "                if x not in coun2ids:\n",
    "                    coun2ids[x]=[ids]\n",
    "                else:\n",
    "                    coun2ids[x].append(ids)\n",
    "    return coun2ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T16:24:05.318728Z",
     "start_time": "2021-12-19T16:22:43.157116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49881 49881\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "datapath='../data/sentences/tydiqa'\n",
    "\n",
    "\n",
    "id_ques=get_qdata(os.path.join('tydiqa','tydiqa-goldp-v1.1-train.json'))\n",
    "ques_id = {j:i for i,j in id_ques.items()}\n",
    "\n",
    "all_q={}\n",
    "all_q_id={}\n",
    "all_q_list=[]\n",
    "for f in os.listdir(datapath):\n",
    "    if 'train' in f and 'train-bn' not in f:\n",
    "        with open(os.path.join(datapath,f),'rb') as f1:\n",
    "            sents=pickle.load(f1)\n",
    "            sents=[x.replace('[START] ','').replace(' [END]','') for x in sents]\n",
    "            name=f.split('.')[0].replace('tydiqa-train-','')\n",
    "            all_q[name]=sents\n",
    "            all_q_id[name]={x:i for i,x in enumerate(sents)}\n",
    "            \n",
    "\n",
    "import pickle\n",
    "\n",
    "datapath='../data/entities/tydiqa'\n",
    "\n",
    "all_ent={}\n",
    "all_ent_id={}\n",
    "\n",
    "for f in os.listdir(datapath):\n",
    "    if 'train' in f and 'train-bn' not in f:\n",
    "        with open(os.path.join(datapath,f),'rb') as f1:\n",
    "            sents=pickle.load(f1)\n",
    "            name=f.split('.')[0].replace('tydiqa-train-','')\n",
    "            all_ent[name]=[x[0]['id'] if len(x)>=1 else '0' for x in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T16:25:04.085335Z",
     "start_time": "2021-12-19T16:24:05.326182Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orig_train = get_orig_id_ent(id_ques,all_q_id, all_ent)\n",
    "coun2ids_train = get_coun2ids(orig_train)\n",
    "langs = ['swahili','bengali','arabic','korean','english','indonesian','japanese','russian',\n",
    "        'telugu','finnish','thai']\n",
    "count_train={}\n",
    "for lang in langs:\n",
    "    count_train[lang]={}\n",
    "    for countr,ids in coun2ids_train.items():\n",
    "        for id_one in ids:\n",
    "            if lang in id_one:\n",
    "                if countr not in count_train[lang]:\n",
    "                    count_train[lang][countr]=1\n",
    "                else:\n",
    "                    count_train[lang][countr]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T15:58:44.813388Z",
     "start_time": "2021-12-19T15:58:44.794840Z"
    }
   },
   "source": [
    "#### dev file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T16:20:32.548362Z",
     "start_time": "2021-12-19T16:20:23.464828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5077 5077\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "datapath='../data/sentences/tydiqa'\n",
    "\n",
    "types='dev'\n",
    "id_ques=get_qdata(os.path.join('tydiqa','tydiqa-goldp-v1.1-{}.json'.format(types)))\n",
    "ques_id = {j:i for i,j in id_ques.items()}\n",
    "\n",
    "all_q={}\n",
    "all_q_id={}\n",
    "all_q_list=[]\n",
    "for f in os.listdir(datapath):\n",
    "    if types in f and 'train-bn' not in f:\n",
    "        with open(os.path.join(datapath,f),'rb') as f1:\n",
    "            sents=pickle.load(f1)\n",
    "            sents=[x.replace('[START] ','').replace(' [END]','') for x in sents]\n",
    "            name=f.split('.')[0].replace('tydiqa-{}-'.format(types),'')\n",
    "            all_q[name]=sents\n",
    "            all_q_id[name]={x:i for i,x in enumerate(sents)}\n",
    "            \n",
    "\n",
    "import pickle\n",
    "\n",
    "datapath='../data/entities/tydiqa'\n",
    "\n",
    "all_ent={}\n",
    "all_ent_id={}\n",
    "\n",
    "for f in os.listdir(datapath):\n",
    "    if types in f and 'train-bn' not in f:\n",
    "        with open(os.path.join(datapath,f),'rb') as f1:\n",
    "            sents=pickle.load(f1)\n",
    "            name=f.split('.')[0].replace('tydiqa-{}-'.format(types),'')\n",
    "            all_ent[name]=[x[0]['id'] if len(x)>=1 else '0' for x in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T16:22:24.455437Z",
     "start_time": "2021-12-19T16:22:18.453195Z"
    }
   },
   "outputs": [],
   "source": [
    "orig_dev = get_orig_id_ent(id_ques,all_q_id, all_ent)\n",
    "coun2ids_dev = get_coun2ids(orig_dev)\n",
    "langs = ['swahili','bengali','arabic','korean','english','indonesian','japanese','russian',\n",
    "        'telugu','finnish','thai']\n",
    "count_dev={}\n",
    "for lang in langs:\n",
    "    count_dev[lang]={}\n",
    "    for countr,ids in coun2ids_dev.items():\n",
    "        for id_one in ids:\n",
    "            if lang in id_one:\n",
    "                if countr not in count_dev[lang]:\n",
    "                    count_dev[lang][countr]=1\n",
    "                else:\n",
    "                    count_dev[lang][countr]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T16:41:47.899188Z",
     "start_time": "2021-12-19T16:41:42.341050Z"
    }
   },
   "outputs": [],
   "source": [
    "langs = ['swahili','bengali','arabic','korean','english','indonesian','japanese','russian',\n",
    "        'telugu','finnish','thai']\n",
    "\n",
    "dev_result={}\n",
    "for lan in langs:\n",
    "    name = lan+'-'\n",
    "    dev_result[lan]={}\n",
    "    for cname,ids in coun2ids_dev.items():\n",
    "        new_examples=[]\n",
    "        new_preds=collections.OrderedDict()\n",
    "        for exam in examples:\n",
    "            if exam.qas_id.startswith(name)==True and exam.qas_id in ids:\n",
    "                new_examples.append(exam)\n",
    "                new_preds[exam.qas_id]=predictions[exam.qas_id]\n",
    "            \n",
    "            \n",
    "        if len(new_examples)!=0:\n",
    "            results = squad_evaluate(new_examples, new_preds)\n",
    "#             print(name,cname,len(new_examples))\n",
    "#             print(results['f1'])\n",
    "            dev_result[lan][cname]=results['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T16:42:53.221539Z",
     "start_time": "2021-12-19T16:42:53.219316Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count_train,count_dev,dev_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
